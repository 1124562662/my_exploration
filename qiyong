
pyyaml== 5.3.1



# class UcbCountNet(nn.Module):
#     def __init__(self, env, embed_dim: int, target: bool = False,
#                  ):
#         super(UcbCountNet, self).__init__()
#         in_dim = 7668
#         self.action_num = env.action_space.n
#         self.target = target
#         self.conv = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=1),
#                                   nn.LeakyReLU(0.7),
#                                   nn.Conv2d(in_channels=2, out_channels=2, kernel_size=2, stride=1, padding=1),
#                                   nn.LeakyReLU(0.7),
#                                   )
#         self.feature_extractor = nn.Sequential(nn.Linear(in_dim, 300),
#                                                nn.LeakyReLU(0.2),
#                                                nn.Linear(300, 100))
#         self.models = nn.ModuleList()
#         for _ in range(self.action_num):
#             if self.target:
#                 mlp = nn.Sequential(nn.Linear(100, embed_dim))
#             else:
#                 mlp = nn.Sequential(nn.Linear(100, 500),
#                                     nn.LeakyReLU(0.2),
#                                     nn.Linear(500, 500),
#                                     nn.LeakyReLU(0.2),
#                                     nn.Linear(500, embed_dim))
#             self.models.append(mlp)
#
#     def forward(self, obs):
#         obs = torch.tensor(obs).to(torch.float32)
#         obs = obs.view((obs.size(0), 1, obs.size(1), -1))
#         obs = self.conv(obs)
#         obs = obs.view(obs.size(0), -1)  # (envsNUm,7668)
#         obs = self.feature_extractor(obs)
#         output_list = []
#         for j in range(self.action_num):
#             output = self.models[j](obs)
#             output_list.append(output)
#         for j in range(self.action_num):
#             if j == 0:
#                 res = output_list[0].unsqueeze(1)
#             else:
#                 res = torch.cat((res, output_list[j].unsqueeze(1)), dim=1)  # (action_nums,env,embed_dim)
#         return res  # (env,action_nums,embed_dim)
#
#     def particular_action_forward(self, obs, action_index):
#         obs = torch.tensor(obs).to(torch.float32)
#         obs = obs.view((obs.size(0), 1, obs.size(1), -1))
#         obs = self.conv(obs)
#         obs = obs.view(obs.size(0), -1)  # (envsNUm,7668)
#         obs = self.feature_extractor(obs)
#         return self.models[int(action_index.item())](obs)  # (embed_dim,)
#
#     @staticmethod
#     def train_RND(device,args,
#                   mb_inds,b_obs, b_actions,
#                   pseudo_ucb_net,pseudo_ucb_target):
#         loss1 = torch.tensor(0, dtype=torch.float32).to(device)
#         for i in range(args.minibatch_size):
#             t_obs = (b_obs[mb_inds][i]).unsqueeze(0)
#             emb = pseudo_ucb_net.particular_action_forward(t_obs, b_actions[mb_inds][i])
#             with torch.no_grad():
#                 emb_t = pseudo_ucb_target.particular_action_forward(t_obs, b_actions[mb_inds][i])
#             loss1 += F.mse_loss(emb, emb_t.detach())
#         loss1 /= torch.tensor(args.minibatch_size, dtype=torch.float32).to(device)
#         pseudo_ucb_net.pseudo_ucb_optimizer.zero_grad()
#         loss1.backward()
#         pseudo_ucb_net.pseudo_ucb_optimizer.step()

class tensorLinear(nn.Module):
    def __init__(self, channel, outd, ind):
        super(tensorLinear, self).__init__()
        self.weight = torch.nn.Parameter(torch.Tensor(channel, outd, ind))
        self.register_parameter("tensorLinear weight", self.weight)
        self.bias = torch.nn.Parameter(torch.Tensor(channel, outd))
        self.register_parameter("tensorLinear bias", self.bias)
        torch.nn.init.orthogonal_(self.weight)

    def forward(self, x):
        print("x.size()",x.size())
        out = torch.matmul( self.weight,x)

        out = torch.add( self.bias.unsqueeze(2).expand(self.bias.size()[0], self.bias.size()[1], out.size()[2]),out) # (actions, 200,envs_nums)
        print("fdsa", out.size())

        return out

    def particular_action_forward(self, obv, action_index):
        out = torch.matmul( obv,self.weight[action_index])
        out = torch.add( out,self.bias[action_index])
        return out

#
# import os
from typing import Any, Callable, Dict, Optional, Type, Union
#
# import gymnasium as gym

from stable_baselines3.common.atari_wrappers import AtariWrapper
# from stable_baselines3.common.monitor import Monitor
# from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecEnv
# from stable_baselines3.common.vec_env.patch_gym import _patch_env
#
#
# def make_vec_env(
#     env_id: Union[str, Callable[..., gym.Env]],
#     n_envs: int = 1,
#     seed: Optional[int] = None,
#     start_index: int = 0,
#     monitor_dir: Optional[str] = None,
#     wrapper_class: Optional[Callable[[gym.Env], gym.Env]] = None,
#     env_kwargs: Optional[Dict[str, Any]] = None,
#     vec_env_cls: Optional[Type[Union[DummyVecEnv, SubprocVecEnv]]] = None,
#     vec_env_kwargs: Optional[Dict[str, Any]] = None,
#     monitor_kwargs: Optional[Dict[str, Any]] = None,
#     wrapper_kwargs: Optional[Dict[str, Any]] = None,
# ) -> VecEnv:
#     """
#     Create a wrapped, monitored ``VecEnv``.
#     By default it uses a ``DummyVecEnv`` which is usually faster
#     than a ``SubprocVecEnv``.
#
#     :param env_id: either the env ID, the env class or a callable returning an env
#     :param n_envs: the number of environments you wish to have in parallel
#     :param seed: the initial seed for the random number generator
#     :param start_index: start rank index
#     :param monitor_dir: Path to a folder where the monitor files will be saved.
#         If None, no file will be written, however, the env will still be wrapped
#         in a Monitor wrapper to provide additional information about training.
#     :param wrapper_class: Additional wrapper to use on the environment.
#         This can also be a function with single argument that wraps the environment in many things.
#         Note: the wrapper specified by this parameter will be applied after the ``Monitor`` wrapper.
#         if some cases (e.g. with TimeLimit wrapper) this can lead to undesired behavior.
#         See here for more details: https://github.com/DLR-RM/stable-baselines3/issues/894
#     :param env_kwargs: Optional keyword argument to pass to the env constructor
#     :param vec_env_cls: A custom ``VecEnv`` class constructor. Default: None.
#     :param vec_env_kwargs: Keyword arguments to pass to the ``VecEnv`` class constructor.
#     :param monitor_kwargs: Keyword arguments to pass to the ``Monitor`` class constructor.
#     :param wrapper_kwargs: Keyword arguments to pass to the ``Wrapper`` class constructor.
#     :return: The wrapped environment
#     """
#     env_kwargs = env_kwargs or {}
#     vec_env_kwargs = vec_env_kwargs or {}
#     monitor_kwargs = monitor_kwargs or {}
#     wrapper_kwargs = wrapper_kwargs or {}
#     assert vec_env_kwargs is not None  # for mypy
#
#     def make_env(rank: int) -> Callable[[], gym.Env]:
#         def _init() -> gym.Env:
#             # For type checker:
#             assert monitor_kwargs is not None
#             assert wrapper_kwargs is not None
#             assert env_kwargs is not None
#
#             if isinstance(env_id, str):
#                 # if the render mode was not specified, we set it to `rgb_array` as default.
#                 kwargs = {"render_mode": "rgb_array"}
#                 kwargs.update(env_kwargs)
#                 try:
#                     env = gym.make(env_id, **kwargs)  # type: ignore[arg-type]
#                 except TypeError:
#                     env = gym.make(env_id, **env_kwargs)
#             else:
#                 env = env_id(**env_kwargs)
#                 # Patch to support gym 0.21/0.26 and gymnasium
#                 env = _patch_env(env)
#
#             if seed is not None:
#                 # Note: here we only seed the action space
#                 # We will seed the env at the next reset
#                 env.action_space.seed(seed + rank)
#             # Wrap the env in a Monitor wrapper
#             # to have additional training information
#             monitor_path = os.path.join(monitor_dir, str(rank)) if monitor_dir is not None else None
#             # Create the monitor folder if needed
#             if monitor_path is not None and monitor_dir is not None:
#                 os.makedirs(monitor_dir, exist_ok=True)
#             env = Monitor(env, filename=monitor_path, **monitor_kwargs)
#             # Optionally, wrap the environment with the provided wrapper
#             if wrapper_class is not None:
#                 env = wrapper_class(env, **wrapper_kwargs)
#             return env
#
#         return _init
#
#     # No custom VecEnv is passed
#     vec_env_cls = SubprocVecEnv
#
#     vec_env = vec_env_cls([make_env(i + start_index) for i in range(n_envs)], **vec_env_kwargs)
#     # Prepare the seeds for the first reset
#     vec_env.seed(seed)
#     return vec_env